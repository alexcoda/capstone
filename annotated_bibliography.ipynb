{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for creating an annotated bibliography of works.\n",
    "\n",
    "Each paper should be read through, and given a brief summary. An example template of what information should be taken from each paper, and how to format it, is given below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "**Section1**\n",
    "\n",
    "[Template](#template)\n",
    "\n",
    "etc...\n",
    "\n",
    "___\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='template'></a>\n",
    "\n",
    "# Paper Title\n",
    "[link to the paper](https://www.google.com)\n",
    "\n",
    "**keywords**: *word1, word2, word3, ...*\n",
    "\n",
    "### Main idea\n",
    "1 or 2 sentences each (in list format) on:\n",
    "1. The task they're trying to solve\n",
    "2. The architecture and features used\n",
    "3. How they do\n",
    "\n",
    "### A Picture is worth a thousand words\n",
    "\n",
    "![The most important figure from the paper, along with this alt-text](https://raw.githubusercontent.com/junyanz/iGAN/master/pics/demo_teaser.jpg)\n",
    "\n",
    "### Utility\n",
    "A few sentence discussion about what is useful from this paper for our project\n",
    "\n",
    "### Criticisms & Failures\n",
    "A few sentence discussion of both:\n",
    "1. Any failures or shortcommings they report on\n",
    "2. Any criticisms of their methodology\n",
    "\n",
    "### Commentary\n",
    "Several sentences for any extraneous commentary on the paper not covered in the above categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='worldmodels'></a>\n",
    "\n",
    "# World Models\n",
    "(https://arxiv.org/pdf/1803.10122.pdf)\n",
    "\n",
    "**keywords**: *Google Brain Project, VAE, RNN, RL*\n",
    "\n",
    "### Main idea\n",
    "1. Generate an environment for an RL agent to learn in. This paper focuses on generating a video game frame by frame and proposes a small network which the RL agent will train in.\n",
    "2. VAE (V) to encode the vision inputs from every frame of a video game, RNN to encode historic information from observing the game (M), Linear Model (C) to convert these encoded inputs to actions. \n",
    "3. Figure below represents the high level diagram of the entire system. The V model does an encoding of the frames and makes a latent vector $z_{t}$ at time $t$. M model is an RNN with another output layer called a Mixture Density Network, which outputs a probability distribution $P(z_{t+1}$ over the next latent visual vector $z_{t+1}$ instead of a deterministic prediction (outputting $z_{t+1}$). the RNN will model $P(z_{t+1} | a_{t}, z_{t}, h_{t})$, where at is the action taken at time $t$ and $h_{t}$ is the hidden state of the RNN at time $t$. The controller model C, is a single Linear Layer which takes the concatenated $[z_{t} h_{t}]$ and outputs the action $a_{t}$. This Controller is trained separately from the V and M.  \n",
    "<img src=\"./worldmodels/HLD.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Utility\n",
    "This is a good Proof of concept that RLs can learn in an environment generated by another model. This paper mainly tries to emulate the fact that humans can predict the future state of the environment and then act accordingly. \n",
    "\n",
    "### Criticisms & Failures\n",
    "1. Since it is a image generative model, this model requires a lot of training, hence the choice for a single linear layer for the Controller network. This model is fitted separately using CMA-ES (Covariance Matrix Adaptation Evolution Strategy) and not trained end-to-end.\n",
    "\n",
    "### Commentary\n",
    "Really Interesting: The paper says: \"if agent needs to learn complex motor skills to walk around its environment, the world model will learn to imitate its own C model that has already learned to walk.\" This way, the world model encodes the short term memory into a long term memory by never removing elements from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
